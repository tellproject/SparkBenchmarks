package ch.ethz.queries.tpch

import ch.ethz.queries.BenchmarkQuery
import org.apache.spark.sql.{DataFrame, DataFrameReader, SQLContext}

/**
  * TPC-H Query 22
  * Savvas Savvides <ssavvides@us.ibm.com>
  *
  */
class Q22 extends BenchmarkQuery {

  override def executeQuery(sqlCxt: SQLContext, dfReader: DataFrameReader): DataFrame = {

    import org.apache.spark.sql.functions._
    import sqlCxt.implicits._

    val customer = dfReader.options(getTableOptions("customer")).load()
    val order = dfReader.options(getTableOptions("orders")).load()
    //    val lineitem = dfReader.options(getTableOptions("lineitem")).load()
    //        val region = dfReader.options(getTableOptions("region", ("useSmallMemory" -> "true"))).load()
    //    val nation = dfReader.options(getTableOptions("nation", ("useSmallMemory" -> "true"))).load()
    //    val supplier = dfReader.options(getTableOptions("supplier")).load()
    //    val partsupp = dfReader.options(getTableOptions("partsupp")).load()
    //    val part = dfReader.options(getTableOptions("part")).load()

    val sub2 = udf { (x: String) => x.substring(0, 2) }
    val phone = udf { (x: String) => x.matches("13|31|23|29|30|18|17") }
    val isNull = udf { (x: Any) => println(x); true }

    val fcustomer = customer.select($"c_acctbal", $"c_custkey", sub2($"c_phone").as("cntrycode"))
      .filter(phone($"cntrycode"))

    val avg_customer = fcustomer.filter($"c_acctbal" > 0.0)
      .agg(avg($"c_acctbal").as("avg_acctbal"))

    order.groupBy($"o_custkey")
      .agg($"o_custkey").select($"o_custkey")
      .join(fcustomer, $"o_custkey" === fcustomer("c_custkey"), "right_outer")
      //.filter("o_custkey is null")
      .filter($"o_custkey".isNull)
      .join(broadcast(avg_customer), $"c_acctbal" > $"avg_acctbal")
      .groupBy($"cntrycode")
      .agg(count($"c_acctbal"), sum($"c_acctbal"))
      .sort($"cntrycode")

  }
}
